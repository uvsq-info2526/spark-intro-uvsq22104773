{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/04 10:54:26 WARN Utils: Your hostname, MacBook-Air-de-Theo.local resolves to a loopback address: 127.0.0.1; using 192.0.0.2 instead (on interface en0)\n",
      "25/11/04 10:54:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/04 10:54:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Exemples avec les formats de stockage\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des prénoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+-----+---+--------+\n",
      "|sexe|         prenom|annee|dep|effectif|\n",
      "+----+---------------+-----+---+--------+\n",
      "|   2|     MARIE-JOSÉ| 1958| 11|      14|\n",
      "|   2|     MARIE-JOSÉ| 1959| 34|      24|\n",
      "|   2|     MARIE-JOSÉ| 1975| 92|       4|\n",
      "|   2|    MARIE-JOSEE| 1958| 57|      11|\n",
      "|   2|  MARIE-JOSEPHE| 1966| 33|       3|\n",
      "|   2|    MARIE-LAURE| 1968| 06|       7|\n",
      "|   2|    MARIE-LAURE| 1971| 51|       9|\n",
      "|   2|    MARIE-LAURE| 1974| 56|      23|\n",
      "|   2|     MARIE-LISE| 1959| 56|      11|\n",
      "|   2|      MARIE-LOU| 1999| 06|       3|\n",
      "|   2|   MARIE-LOUISE| 1915| 68|       6|\n",
      "|   2|   MARIE-LOUISE| 1917| 12|       6|\n",
      "|   2|   MARIE-LOUISE| 1921| 15|      16|\n",
      "|   2|   MARIE-LOUISE| 1930| 03|      10|\n",
      "|   2|   MARIE-LOUISE| 1946| 73|      13|\n",
      "|   2|   MARIE-LOUISE| 1955| 14|       6|\n",
      "|   2|     MARIE-LUCE| 1948| 88|       3|\n",
      "|   2|MARIE-MADELEINE| 1926|974|       3|\n",
      "|   2|MARIE-MADELEINE| 1941| 61|       3|\n",
      "|   2|   MARIE-NOËLLE| 1952| 27|       7|\n",
      "+----+---------------+-----+---+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Charge un fichier texte et convertit les lignes en \"Row\".\n",
    "lines = sc.textFile(\"prenoms_sample.txt\")\n",
    "prenoms_as_rdd = lines.map(lambda l: l.split(\";\"))\\\n",
    "    .map(lambda p: Row(\\\n",
    "        sexe=int(p[0]),\\\n",
    "        prenom=p[1],\\\n",
    "        annee=int(p[2]),\\\n",
    "        dep=p[3],\\\n",
    "        effectif=int(p[4])))\n",
    "\n",
    "# Infère le schéma et enregistre le DataFrame comme une table.\n",
    "prenoms = spark.createDataFrame(prenoms_as_rdd)\n",
    "prenoms.createOrReplaceTempView(\"prenoms\")\n",
    "prenoms.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des départements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+----+--------------------+--------------------+--------------------+\n",
      "|dep|reg|cheflieu|tncc|                 ncc|              nccenr|             libelle|\n",
      "+---+---+--------+----+--------------------+--------------------+--------------------+\n",
      "|  1| 84|   01053|   5|                 AIN|                 Ain|                 Ain|\n",
      "|  2| 32|   02408|   5|               AISNE|               Aisne|               Aisne|\n",
      "|  3| 84|   03190|   5|              ALLIER|              Allier|              Allier|\n",
      "|  4| 93|   04070|   4|ALPES DE HAUTE PR...|Alpes-de-Haute-Pr...|Alpes-de-Haute-Pr...|\n",
      "|  5| 93|   05061|   4|        HAUTES ALPES|        Hautes-Alpes|        Hautes-Alpes|\n",
      "|  6| 93|   06088|   4|     ALPES MARITIMES|     Alpes-Maritimes|     Alpes-Maritimes|\n",
      "|  7| 84|   07186|   5|             ARDECHE|             Ardèche|             Ardèche|\n",
      "|  8| 44|   08105|   4|            ARDENNES|            Ardennes|            Ardennes|\n",
      "|  9| 76|   09122|   5|              ARIEGE|              Ariège|              Ariège|\n",
      "| 10| 44|   10387|   5|                AUBE|                Aube|                Aube|\n",
      "| 11| 76|   11069|   5|                AUDE|                Aude|                Aude|\n",
      "| 12| 76|   12202|   5|             AVEYRON|             Aveyron|             Aveyron|\n",
      "| 13| 93|   13055|   4|    BOUCHES DU RHONE|    Bouches-du-Rhône|    Bouches-du-Rhône|\n",
      "| 14| 28|   14118|   2|            CALVADOS|            Calvados|            Calvados|\n",
      "| 15| 84|   15014|   2|              CANTAL|              Cantal|              Cantal|\n",
      "| 16| 75|   16015|   3|            CHARENTE|            Charente|            Charente|\n",
      "| 17| 75|   17300|   3|   CHARENTE MARITIME|   Charente-Maritime|   Charente-Maritime|\n",
      "| 18| 24|   18033|   2|                CHER|                Cher|                Cher|\n",
      "| 19| 75|   19272|   3|             CORREZE|             Corrèze|             Corrèze|\n",
      "| 21| 27|   21231|   3|           COTE D OR|           Côte-d'Or|           Côte-d'Or|\n",
      "+---+---+--------+----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"dpts.txt\")\n",
    "depts_as_rdd = lines\\\n",
    "    .filter(lambda l: \"dep\" not in l and \"2A\" not in l and \"2B\" not in l)\\\n",
    "    .map(lambda l: l.split(\",\"))\\\n",
    "    .map(lambda p: Row(\\\n",
    "        dep=int(p[0]),\\\n",
    "        reg=int(p[1]),\\\n",
    "        cheflieu=p[2],\\\n",
    "        tncc=p[3],\\\n",
    "        ncc=p[4],\\\n",
    "        nccenr=p[6],\\\n",
    "        libelle=p[6]))\n",
    "\n",
    "depts = spark.createDataFrame(depts_as_rdd)\n",
    "depts.createOrReplaceTempView(\"depts\")\n",
    "depts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarder les données au format parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les prénoms partitionnés par départements et années et compressés (Snappy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prenoms.write\\\n",
    "    .partitionBy('dep', 'annee')\\\n",
    "        .format('parquet')\\\n",
    "            .save('prenomsParDeptsEtAnnees.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les prénoms partitionnés par départements et années et compressés (gzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prenoms.write\\\n",
    "    .partitionBy('dep', 'annee')\\\n",
    "        .option(\"compression\", \"gzip\")\\\n",
    "            .format('parquet')\\\n",
    "                .save(\"prenomsParDeptsEtAnnees.gzip.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les départements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "depts.write\\\n",
    "    .format(\"parquet\")\\\n",
    "        .save(\"depts.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv (3.9.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
