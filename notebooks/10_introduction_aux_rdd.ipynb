{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/21 18:49:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/10/21 18:49:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"Notebook\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Une fonction pour simplifier l'accès aux données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_field(s: str, field_number: int, sep: str = ';') -> str:\n",
    "    fields = s.split(sep)\n",
    "    return fields[field_number] if (field_number < len(fields)) else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "CASSIOPEE\n",
      "2009\n",
      "33\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(extract_field(\"2;CASSIOPEE;2009;33;3\", 0))\n",
    "print(extract_field(\"2;CASSIOPEE;2009;33;3\", 1))\n",
    "print(extract_field(\"2;CASSIOPEE;2009;33;3\", 2))\n",
    "print(extract_field(\"2;CASSIOPEE;2009;33;3\", 3))\n",
    "print(extract_field(\"2;CASSIOPEE;2009;33;3\", 4))\n",
    "print(extract_field(\"2;CASSIOPEE;2009;33;3\", 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charger les données\n",
    "1. Créer le RDD `lignes` à partir du répertoire `prenoms_sample.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2;MARIE-JOSÉ;1955;30;21', '2;MARIE-JOSÉ;1956;56;9', '2;MARIE-JOSÉ;1966;64;29', '2;MARIE-JOSEE;1951;59;22', '2;MARIE-JOSEE;1954;54;6', '2;MARIE-JOSEE;1954;67;15', '2;MARIE-JOSEPH;1907;56;4', '2;MARIE-JOSEPHE;1942;75;11', '2;MARIE-JOSEPHE;1951;78;3', '2;MARIE-LAURE;1958;61;6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lignes = sc.textFile(\"prenoms_sample.txt\")\n",
    "print(lignes.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer les lignes en prénoms\n",
    "1. En appliquant la méthode `map`, créer le RDD `prenoms` à partir de `lignes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2', 'MARIE-JOSÉ', 1955, '30', 21)\n",
      "('2', 'MARIE-JOSÉ', 1956, '56', 9)\n",
      "('2', 'MARIE-JOSÉ', 1966, '64', 29)\n",
      "('2', 'MARIE-JOSEE', 1951, '59', 22)\n",
      "('2', 'MARIE-JOSEE', 1954, '54', 6)\n",
      "('2', 'MARIE-JOSEE', 1954, '67', 15)\n",
      "('2', 'MARIE-JOSEPH', 1907, '56', 4)\n",
      "('2', 'MARIE-JOSEPHE', 1942, '75', 11)\n",
      "('2', 'MARIE-JOSEPHE', 1951, '78', 3)\n",
      "('2', 'MARIE-LAURE', 1958, '61', 6)\n"
     ]
    }
   ],
   "source": [
    "prenoms = lignes.map(lambda l: (\n",
    "    extract_field(l, 0)[0],\n",
    "    extract_field(l, 1),\n",
    "    int(extract_field(l, 2)),\n",
    "    extract_field(l, 3),\n",
    "    int(extract_field(l, 4))\n",
    "))\n",
    "for n in prenoms.take(10):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interroger les données\n",
    "La documentation des méthodes d'un RDD est disponible ([RDD](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html)).\n",
    "\n",
    "1. Rappeler ce que sont les *transformations* et les *actions*\n",
    "\n",
    "En Spark, les *transformations* décrivent les opérations à faire sur les données sans les exécuter, tandis que les *actions* déclenchent réellement leur exécution pour produire un résultat.\n",
    "\n",
    "2. Donner, pour chaque prénom, son nombre d'occurences (`map` et `reduceByKey`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MARIE-JOSÉ', 3)\n",
      "('MARIE-JOSEPH', 1)\n",
      "('MARIE-JOSEPHE', 2)\n",
      "('MARIE-LAURE', 2)\n",
      "('MARIE-NADEGE', 1)\n",
      "('MARIE-NOËLLE', 3)\n",
      "('MARIE-THÉRÈSE', 9)\n",
      "('MARIELLE', 1)\n",
      "('MARIETTE', 2)\n",
      "('MARILENE', 1)\n"
     ]
    }
   ],
   "source": [
    "occ_prenoms = prenoms.map(lambda prenom: (prenom[1], 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "for n in occ_prenoms.take(10):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Donner le nombre total de naissances avec un prénom féminin (`filter`, `map`, `reduce` ou `sum`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41548\n"
     ]
    }
   ],
   "source": [
    "nb_naissance_feminin = prenoms.filter(lambda sexe: sexe[0] == '2').map(lambda prenom: prenom[4]).sum()\n",
    "print(nb_naissance_feminin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Donner l'effectif maximal et minimal par prénom (`map`, `aggregateByKey`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MARIE-JOSÉ', (9, 29))\n",
      "('MARIE-JOSEPH', (4, 4))\n",
      "('MARIE-JOSEPHE', (3, 11))\n",
      "('MARIE-LAURE', (5, 6))\n",
      "('MARIE-NADEGE', (5, 5))\n",
      "('MARIE-NOËLLE', (7, 12))\n",
      "('MARIE-THÉRÈSE', (3, 20))\n",
      "('MARIELLE', (5, 5))\n",
      "('MARIETTE', (9, 28))\n",
      "('MARILENE', (3, 3))\n"
     ]
    }
   ],
   "source": [
    "max_min_prenoms = prenoms.map(lambda prenom: (prenom[1], prenom[4])).aggregateByKey(\n",
    "    (float('inf'), float('-inf')),\n",
    "    lambda acc, v: (min(acc[0], v), max(acc[1], v)),\n",
    "    lambda acc1, acc2: (min(acc1[0], acc2[0]), max(acc1[1], acc2[1]))\n",
    "    )\n",
    "\n",
    "for n in max_min_prenoms.take(10):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sur le modèle des prénoms, charger les données des départements\n",
    "1. Donner, pour chaque nom de département, le prénom le plus fréquent depuis l'année 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpts = sc.textFile(\"dpts.txt\")\n",
    "dpts.filter(lambda l: l.startswith(\"dep\") == False)\\\n",
    "    .saveAsTextFile(\"dpts_sample.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('01', 84, '01053', 5, 'AIN', 'Ain', 'Ain')\n",
      "('02', 32, '02408', 5, 'AISNE', 'Aisne', 'Aisne')\n",
      "('03', 84, '03190', 5, 'ALLIER', 'Allier', 'Allier')\n",
      "('04', 93, '04070', 4, 'ALPES DE HAUTE PROVENCE', 'Alpes-de-Haute-Provence', 'Alpes-de-Haute-Provence')\n",
      "('05', 93, '05061', 4, 'HAUTES ALPES', 'Hautes-Alpes', 'Hautes-Alpes')\n",
      "('06', 93, '06088', 4, 'ALPES MARITIMES', 'Alpes-Maritimes', 'Alpes-Maritimes')\n",
      "('07', 84, '07186', 5, 'ARDECHE', 'Ardèche', 'Ardèche')\n",
      "('08', 44, '08105', 4, 'ARDENNES', 'Ardennes', 'Ardennes')\n",
      "('09', 76, '09122', 5, 'ARIEGE', 'Ariège', 'Ariège')\n",
      "('10', 44, '10387', 5, 'AUBE', 'Aube', 'Aube')\n"
     ]
    }
   ],
   "source": [
    "lignes = sc.textFile(\"dpts_sample.txt\")\n",
    "\n",
    "dpts = lignes.map(lambda l: (\n",
    "    extract_field(l, 0, ','),\n",
    "    int(extract_field(l, 1, ',')),\n",
    "    (extract_field(l, 2, ',')),\n",
    "    int(extract_field(l, 3, ',')),\n",
    "    extract_field(l, 4, ','),\n",
    "    extract_field(l, 5, ','),\n",
    "    extract_field(l, 6, ',')\n",
    "))\n",
    "for n in dpts.take(10):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('VAR', 'MANON')\n",
      "('MORBIHAN', 'JEANNE')\n",
      "('SEINE ET MARNE', 'EMMA')\n",
      "('HAUTE SAONE', 'LILOU')\n",
      "('LOIRE ATLANTIQUE', 'HUGO')\n",
      "('MEURTHE ET MOSELLE', 'LIAM')\n",
      "('OISE', 'ESTEBAN')\n",
      "('AUBE', '_PRENOMS_RARES')\n",
      "('VOSGES', 'COLINE')\n",
      "('VIENNE', '_PRENOMS_RARES')\n"
     ]
    }
   ],
   "source": [
    "freq_depts_prenoms = prenoms.filter(lambda prenom: prenom[2] >= 2000)\\\n",
    "    .map(lambda prenom: ((prenom[1], prenom[3]), prenom[4]))\\\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "freq_by_dept = freq_depts_prenoms.map(lambda x: (x[0][1], (x[0][0], x[1])))  # clé = code_dept, valeur = (prenom, nb_naissances)\n",
    "\n",
    "dpts_noms = dpts.map(lambda dpt: (dpt[0], dpt[4]))  # clé = code_dept, valeur = nom_dept\n",
    "\n",
    "jointure = freq_by_dept.join(dpts_noms)\\\n",
    "    .reduceByKey(lambda a, b: a if a[0][1] > b[0][1] else b)\\\n",
    "    .map(lambda x: (x[1][1], x[1][0][0]))\n",
    "\n",
    "for n in jointure.take(10):\n",
    "   print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv (3.9.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
